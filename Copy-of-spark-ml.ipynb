{"nbformat":4,"nbformat_minor":0,"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookName":"03-spark-ml","notebookOrigID":835564910129657,"widgets":{}},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.2"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"TOC","toc_cell":true,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"288px"},"toc_section_display":true,"toc_window_display":true},"colab":{"name":"Copy of spark-ml.ipynb","provenance":[{"file_id":"https://github.com/flatiron-school/ds-spark/blob/main/spark-ml.ipynb","timestamp":1636140115163}]}},"cells":[{"cell_type":"markdown","metadata":{"toc":true,"id":"j53LeieJguxQ"},"source":["<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n","<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Objectives\" data-toc-modified-id=\"Objectives-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Objectives</a></span></li><li><span><a href=\"#Set-Up-Spark-Context\" data-toc-modified-id=\"Set-Up-Spark-Context-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Set Up Spark Context</a></span></li><li><span><a href=\"#Loading-and-Preprocessing-the-Example-Data\" data-toc-modified-id=\"Loading-and-Preprocessing-the-Example-Data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Loading and Preprocessing the Example Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Process-the-Features\" data-toc-modified-id=\"Process-the-Features-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Process the Features</a></span></li></ul></li><li><span><a href=\"#Train-and-Predict-with-Random-Forest\" data-toc-modified-id=\"Train-and-Predict-with-Random-Forest-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Train and Predict with Random Forest</a></span></li><li><span><a href=\"#Evaluate-the-Model\" data-toc-modified-id=\"Evaluate-the-Model-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Evaluate the Model</a></span></li><li><span><a href=\"#Using-Pipeline-and-Performing-a-Grid-Search-for-Optimal-Parameters\" data-toc-modified-id=\"Using-Pipeline-and-Performing-a-Grid-Search-for-Optimal-Parameters-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Using Pipeline and Performing a Grid Search for Optimal Parameters</a></span><ul class=\"toc-item\"><li><span><a href=\"#Evaluate-with-Cross-Validation-to-Find-Optimal-Model\" data-toc-modified-id=\"Evaluate-with-Cross-Validation-to-Find-Optimal-Model-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Evaluate with Cross Validation to Find Optimal Model</a></span></li></ul></li></ul></div>"]},{"cell_type":"markdown","metadata":{"id":"f28D9GIIguxV"},"source":["<a href=\"https://colab.research.google.com/github/flatiron-school/ds-spark/blob/main/spark-ml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"code","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"5c378d7f-7259-4e33-bbaf-7627af7cbb7a","showTitle":false,"title":""},"id":"nfW4ViL8guxW","executionInfo":{"status":"ok","timestamp":1636139554639,"user_tz":240,"elapsed":78107,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"72fb777e-2a74-4b88-8c99-f6f8f59581ee","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Run for Google Colab environment\n","!pip install pyspark\n","!apt install openjdk-8-jdk-headless -qq\n","!pip install mlflow #all the models we learned from sklearn (random forest classifier, etc.) for spark"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyspark\n","  Downloading pyspark-3.2.0.tar.gz (281.3 MB)\n","\u001b[K     |████████████████████████████████| 281.3 MB 29 kB/s \n","\u001b[?25hCollecting py4j==0.10.9.2\n","  Downloading py4j-0.10.9.2-py2.py3-none-any.whl (198 kB)\n","\u001b[K     |████████████████████████████████| 198 kB 62.8 MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.2.0-py2.py3-none-any.whl size=281805912 sha256=bc6a95d5a5cd33c59fca9bd89c488163ccb920ea2878d4b0cc38b5b1f523207b\n","  Stored in directory: /root/.cache/pip/wheels/0b/de/d2/9be5d59d7331c6c2a7c1b6d1a4f463ce107332b1ecd4e80718\n","Successfully built pyspark\n","Installing collected packages: py4j, pyspark\n","Successfully installed py4j-0.10.9.2 pyspark-3.2.0\n","The following additional packages will be installed:\n","  openjdk-8-jre-headless\n","Suggested packages:\n","  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra\n","  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n","  fonts-wqy-zenhei fonts-indic\n","The following NEW packages will be installed:\n","  openjdk-8-jdk-headless openjdk-8-jre-headless\n","0 upgraded, 2 newly installed, 0 to remove and 37 not upgraded.\n","Need to get 36.5 MB of archives.\n","After this operation, 143 MB of additional disk space will be used.\n","Selecting previously unselected package openjdk-8-jre-headless:amd64.\n","(Reading database ... 155219 files and directories currently installed.)\n","Preparing to unpack .../openjdk-8-jre-headless_8u292-b10-0ubuntu1~18.04_amd64.deb ...\n","Unpacking openjdk-8-jre-headless:amd64 (8u292-b10-0ubuntu1~18.04) ...\n","Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n","Preparing to unpack .../openjdk-8-jdk-headless_8u292-b10-0ubuntu1~18.04_amd64.deb ...\n","Unpacking openjdk-8-jdk-headless:amd64 (8u292-b10-0ubuntu1~18.04) ...\n","Setting up openjdk-8-jre-headless:amd64 (8u292-b10-0ubuntu1~18.04) ...\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n","Setting up openjdk-8-jdk-headless:amd64 (8u292-b10-0ubuntu1~18.04) ...\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n","Collecting mlflow\n","  Downloading mlflow-1.21.0-py3-none-any.whl (16.9 MB)\n","\u001b[K     |████████████████████████████████| 16.9 MB 43 kB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mlflow) (21.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.1.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.19.5)\n","Collecting alembic<=1.4.1\n","  Downloading alembic-1.4.1.tar.gz (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 67.4 MB/s \n","\u001b[?25hCollecting querystring-parser\n","  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.3.0)\n","Collecting gitpython>=2.1.0\n","  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n","\u001b[K     |████████████████████████████████| 180 kB 64.8 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata!=4.7.0,>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (4.8.1)\n","Collecting prometheus-flask-exporter\n","  Downloading prometheus_flask_exporter-0.18.5-py3-none-any.whl (17 kB)\n","Requirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from mlflow) (0.4.2)\n","Collecting databricks-cli>=0.8.7\n","  Downloading databricks-cli-0.16.2.tar.gz (58 kB)\n","\u001b[K     |████████████████████████████████| 58 kB 4.6 MB/s \n","\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from mlflow) (2018.9)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from mlflow) (0.3)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (7.1.2)\n","Collecting docker>=4.0.0\n","  Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB)\n","\u001b[K     |████████████████████████████████| 146 kB 53.4 MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.17.3 in /usr/local/lib/python3.7/dist-packages (from mlflow) (2.23.0)\n","Requirement already satisfied: Flask in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.1.4)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 54.0 MB/s \n","\u001b[?25hCollecting gunicorn\n","  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 8.3 MB/s \n","\u001b[?25hRequirement already satisfied: sqlalchemy in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.4.25)\n","Requirement already satisfied: protobuf>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (3.17.3)\n","Collecting Mako\n","  Downloading Mako-1.1.5-py2.py3-none-any.whl (75 kB)\n","\u001b[K     |████████████████████████████████| 75 kB 4.6 MB/s \n","\u001b[?25hCollecting python-editor>=0.3\n","  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from alembic<=1.4.1->mlflow) (2.8.2)\n","Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow) (0.8.9)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow) (1.15.0)\n","Collecting websocket-client>=0.32.0\n","  Downloading websocket_client-1.2.1-py2.py3-none-any.whl (52 kB)\n","\u001b[K     |████████████████████████████████| 52 kB 1.4 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from gitpython>=2.1.0->mlflow) (3.7.4.3)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.5 MB/s \n","\u001b[?25hCollecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata!=4.7.0,>=3.7.0->mlflow) (3.6.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (3.0.4)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->mlflow) (1.1.2)\n","Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow) (2.11.3)\n","Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow) (1.1.0)\n","Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow) (1.0.1)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask->mlflow) (2.0.1)\n","Requirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.7/dist-packages (from gunicorn->mlflow) (57.4.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->mlflow) (2.4.7)\n","Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from prometheus-flask-exporter->mlflow) (0.12.0)\n","Building wheels for collected packages: alembic, databricks-cli\n","  Building wheel for alembic (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for alembic: filename=alembic-1.4.1-py2.py3-none-any.whl size=158172 sha256=80180332fee20bbb30937c4c9f27f191256ba375ff20827168b0c8f071c3f4b8\n","  Stored in directory: /root/.cache/pip/wheels/be/5d/0a/9e13f53f4f5dfb67cd8d245bb7cdffe12f135846f491a283e3\n","  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for databricks-cli: filename=databricks_cli-0.16.2-py3-none-any.whl size=106811 sha256=82111401ce693ff3cd0df67fbd375e4333bf58f2c814b023ddc74d68c647f02f\n","  Stored in directory: /root/.cache/pip/wheels/f4/5c/ed/e1ce20a53095f63b27b4964abbad03e59cf3472822addf7d29\n","Successfully built alembic databricks-cli\n","Installing collected packages: smmap, websocket-client, python-editor, Mako, gitdb, querystring-parser, pyyaml, prometheus-flask-exporter, gunicorn, gitpython, docker, databricks-cli, alembic, mlflow\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed Mako-1.1.5 alembic-1.4.1 databricks-cli-0.16.2 docker-5.0.3 gitdb-4.0.9 gitpython-3.1.24 gunicorn-20.1.0 mlflow-1.21.0 prometheus-flask-exporter-0.18.5 python-editor-1.0.4 pyyaml-6.0 querystring-parser-1.2.4 smmap-5.0.0 websocket-client-1.2.1\n"]}]},{"cell_type":"code","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"c7b5bd71-ac04-4b84-9a90-2e2a3b9d3670","showTitle":false,"title":""},"id":"WfaTbtO8guxX","executionInfo":{"status":"ok","timestamp":1636139565008,"user_tz":240,"elapsed":324,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["import pyspark\n","from pyspark.ml.regression import RandomForestRegressor\n","from pyspark.ml import feature\n","from pyspark.ml.feature import StringIndexer, VectorAssembler, OneHotEncoder\n","from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit, CrossValidator\n","from pyspark.ml.evaluation import RegressionEvaluator\n","from pyspark.ml import Pipeline"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"4XhMyBvdguxY","executionInfo":{"status":"ok","timestamp":1636139574597,"user_tz":240,"elapsed":459,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"3e865de1-972b-4acb-dd30-a903925a5ae4","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Get data directly from repo\n","!wget https://github.com/flatiron-school/ds-spark/releases/download/v1.0/US_births_2000-2014_SSA.csv"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["--2021-11-05 19:12:54--  https://github.com/flatiron-school/ds-spark/releases/download/v1.0/US_births_2000-2014_SSA.csv\n","Resolving github.com (github.com)... 140.82.114.3\n","Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://github-releases.githubusercontent.com/379727666/12461180-d431-11eb-8163-e15e52afc9a9?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211105%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211105T191254Z&X-Amz-Expires=300&X-Amz-Signature=0e40316431f431e37205518196c901fcfe65cf2923bbfc5638f558f4c47483c5&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=379727666&response-content-disposition=attachment%3B%20filename%3DUS_births_2000-2014_SSA.csv&response-content-type=application%2Foctet-stream [following]\n","--2021-11-05 19:12:54--  https://github-releases.githubusercontent.com/379727666/12461180-d431-11eb-8163-e15e52afc9a9?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211105%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211105T191254Z&X-Amz-Expires=300&X-Amz-Signature=0e40316431f431e37205518196c901fcfe65cf2923bbfc5638f558f4c47483c5&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=379727666&response-content-disposition=attachment%3B%20filename%3DUS_births_2000-2014_SSA.csv&response-content-type=application%2Foctet-stream\n","Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.108.154, 185.199.109.154, 185.199.110.154, ...\n","Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.108.154|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 96748 (94K) [application/octet-stream]\n","Saving to: ‘US_births_2000-2014_SSA.csv’\n","\n","US_births_2000-2014 100%[===================>]  94.48K  --.-KB/s    in 0.01s   \n","\n","2021-11-05 19:12:54 (6.52 MB/s) - ‘US_births_2000-2014_SSA.csv’ saved [96748/96748]\n","\n"]}]},{"cell_type":"markdown","metadata":{"heading_collapsed":true,"id":"z0o3v4uGguxZ"},"source":["# Objectives"]},{"cell_type":"markdown","metadata":{"hidden":true,"id":"0toBSSBmguxZ"},"source":["- Use `pyspark` to build machine learning models"]},{"cell_type":"markdown","metadata":{"heading_collapsed":true,"id":"Up2jnez3guxa"},"source":["# Set Up Spark Context"]},{"cell_type":"code","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"c7b5bd71-ac04-4b84-9a90-2e2a3b9d3670","showTitle":false,"title":""},"hidden":true,"id":"LDSWEFpjguxb","executionInfo":{"status":"ok","timestamp":1636139677156,"user_tz":240,"elapsed":6710,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["#Whenever you use spark framework, you need to open a session\n","#this is very basic\n","spark = pyspark.sql.SparkSession.builder.getOrCreate()\n","sc = spark.sparkContext"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"heading_collapsed":true,"id":"aUirNWSFguxb"},"source":["# Loading and Preprocessing the Example Data"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"af6b675c-1cb3-4b11-9882-1d7ba0b48d47","showTitle":false,"title":""},"hidden":true,"id":"P3DWlhPSguxc"},"source":["This example assumes that we have a holdout validation dataset somewhere else, so we don't need to perform a train-test split, we only need to perform cross validation"]},{"cell_type":"code","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"a7ff68e5-303d-4c4d-92c2-7a011fb94797","showTitle":false,"title":""},"hidden":true,"scrolled":true,"id":"ejYUgMTDguxc","executionInfo":{"status":"ok","timestamp":1636139690725,"user_tz":240,"elapsed":7707,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["# Load the file since we downloaded it earlie\n","df = spark.read.format('csv').option('header', 'true').\\\n","load('US_births_2000-2014_SSA.csv')"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"f6263aeb-3b11-42af-a198-a568bcee1aeb","showTitle":false,"title":""},"hidden":true,"id":"NQUDVPc_guxc","executionInfo":{"status":"ok","timestamp":1636139694426,"user_tz":240,"elapsed":1042,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"107a00c1-6417-456a-984f-ed1561945080","colab":{"base_uri":"https://localhost:8080/","height":143}},"source":["df.toPandas().head(3)"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>year</th>\n","      <th>month</th>\n","      <th>date_of_month</th>\n","      <th>day_of_week</th>\n","      <th>births</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2000</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>9083</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2000</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>7</td>\n","      <td>8006</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2000</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>11363</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   year month date_of_month day_of_week births\n","0  2000     1             1           6   9083\n","1  2000     1             2           7   8006\n","2  2000     1             3           1  11363"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","metadata":{"heading_collapsed":true,"hidden":true,"id":"QcXFTGRKguxd"},"source":["## Process the Features"]},{"cell_type":"code","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"359de235-b355-4864-a9db-e11099b59f69","showTitle":false,"title":""},"hidden":true,"id":"FaaNEwiEguxd","executionInfo":{"status":"ok","timestamp":1636139708595,"user_tz":240,"elapsed":153,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"102d0877-9bb1-4d48-a681-cff178fa2be3","colab":{"base_uri":"https://localhost:8080/"}},"source":["df.dtypes"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('year', 'string'),\n"," ('month', 'string'),\n"," ('date_of_month', 'string'),\n"," ('day_of_week', 'string'),\n"," ('births', 'string')]"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"d39ba897-3457-4e14-b998-f25b26c409da","showTitle":false,"title":""},"hidden":true,"id":"EDsfNajAguxd","executionInfo":{"status":"ok","timestamp":1636139726090,"user_tz":240,"elapsed":314,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["df = df.withColumn('births', df['births'].cast('int'))\n","df = df.withColumn('day_of_week', df['day_of_week'].cast('int'))\n","df = df.withColumn('date_of_month', df['date_of_month'].cast('int'))\n","df = df.withColumn('month', df['month'].cast('int'))\n","df = df.withColumn('year', df['year'].cast('int'))"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"jYIx0qN-h0sh","executionInfo":{"status":"ok","timestamp":1636139752723,"user_tz":240,"elapsed":144,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"c618d0bd-7462-4e18-b36f-85032bd09912","colab":{"base_uri":"https://localhost:8080/"}},"source":["type(df)"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["pyspark.sql.dataframe.DataFrame"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"86a93804-96e8-4885-bb5b-c54e419a0916","showTitle":false,"title":""},"hidden":true,"id":"fVX2p5R8guxe","executionInfo":{"status":"ok","timestamp":1636139757743,"user_tz":240,"elapsed":2130,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"941516cb-b087-4146-8740-e455f08019da","colab":{"base_uri":"https://localhost:8080/"}},"source":["ohe = feature.OneHotEncoder(inputCols=['date_of_month',\n","                                                'day_of_week'],\n","                                     outputCols=['date_vec',\n","                                                  'day_vec'],\n","                                     dropLast=True)\n","one_hot_encoded = ohe.fit(df).transform(df)\n","one_hot_encoded.head()"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Row(year=2000, month=1, date_of_month=1, day_of_week=6, births=9083, date_vec=SparseVector(31, {1: 1.0}), day_vec=SparseVector(7, {6: 1.0}))"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"62567225-2c4a-4ff3-8b70-a20c0a2b46af","showTitle":false,"title":""},"hidden":true,"id":"hSLxeqbrguxe"},"source":["Note the 'SparseVector' we've created!"]},{"cell_type":"code","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"9df01298-60df-45b1-b558-829a14477cbd","showTitle":false,"title":""},"hidden":true,"id":"2nv4TCoBguxh","executionInfo":{"status":"ok","timestamp":1636139774655,"user_tz":240,"elapsed":391,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["features = ['year', 'month', 'date_of_month', 'day_of_week']\n","\n","target = 'births'\n","\n","vector = VectorAssembler(inputCols=features, outputCol='features')\n","vectorized_df = vector.transform(one_hot_encoded)"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"7565c684-3a6c-4e7f-9ac1-0c8544ce6fae","showTitle":false,"title":""},"hidden":true,"id":"z27WMcOvguxh"},"source":["The Vector Assembler is often what we want when we're building a model in Spark. [How does the VectorAssembler work?](https://spark.apache.org/docs/2.1.0/ml-features.html#vectorassembler)"]},{"cell_type":"code","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"b32355db-6351-431b-9bf4-7ceefef823d4","showTitle":false,"title":""},"hidden":true,"id":"-MkgfRg2guxi","executionInfo":{"status":"ok","timestamp":1636139793474,"user_tz":240,"elapsed":167,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"e7de5bf7-c21f-442c-efcf-af0d9cd717e4","colab":{"base_uri":"https://localhost:8080/"}},"source":["vectorized_df.columns"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['year',\n"," 'month',\n"," 'date_of_month',\n"," 'day_of_week',\n"," 'births',\n"," 'date_vec',\n"," 'day_vec',\n"," 'features']"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","metadata":{"heading_collapsed":true,"id":"Bxde21doguxi"},"source":["# Train and Predict with Random Forest"]},{"cell_type":"markdown","metadata":{"id":"a-nubbxbidWq"},"source":["*Creating a featuresCol is the additional step we need to take in spark compared to sklearn*"]},{"cell_type":"code","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"5a4278a2-0a2b-4fb2-9fcc-86545c194c1a","showTitle":false,"title":""},"hidden":true,"id":"8G2mffN4guxi","executionInfo":{"status":"ok","timestamp":1636139822886,"user_tz":240,"elapsed":4547,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["rf_model = RandomForestRegressor(featuresCol='features',\n","                                 labelCol='births',\n","                                 predictionCol=\"prediction\").fit(vectorized_df)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"e2a65c25-7be6-43b3-ad0a-a0efec038fac","showTitle":false,"title":""},"hidden":true,"id":"VA3v7TJlguxi","executionInfo":{"status":"ok","timestamp":1636139829477,"user_tz":240,"elapsed":719,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"9228b867-8477-4464-e9a3-d545f67904c4","colab":{"base_uri":"https://localhost:8080/"}},"source":["predictions = rf_model.transform(vectorized_df).select(\"births\", \"prediction\")\n","predictions.head(3)"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Row(births=9083, prediction=8719.05738715514),\n"," Row(births=8006, prediction=7743.196122309506),\n"," Row(births=11363, prediction=11733.547464357749)]"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","metadata":{"heading_collapsed":true,"id":"LHkRLhn5guxi"},"source":["# Evaluate the Model"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"8f61139f-c7eb-4319-9dea-d62cfce1cb6d","showTitle":false,"title":""},"hidden":true,"id":"4EFsH5iDguxi"},"source":["Let's evaluate our model! [Here](https://spark.apache.org/docs/2.2.0/mllib-evaluation-metrics.html) is a reference for the many metrics available in Spark."]},{"cell_type":"code","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"30d59b5c-5586-4984-a964-4ff9945aeaf8","showTitle":false,"title":""},"hidden":true,"id":"3-gjJWQJguxi"},"source":["from pyspark.ml.evaluation import RegressionEvaluator"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"30d59b5c-5586-4984-a964-4ff9945aeaf8","showTitle":false,"title":""},"hidden":true,"id":"1nlUpFiqguxj"},"source":["evaluator = RegressionEvaluator(predictionCol='prediction', labelCol='births')\n","\n","evaluator.evaluate(predictions, {evaluator.metricName:\"r2\"})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"eb8adf31-10e4-4b94-90bc-b1d9a77407c8","showTitle":false,"title":""},"hidden":true,"id":"XiWPJRWIguxj"},"source":["evaluator.evaluate(predictions, {evaluator.metricName:\"mae\"})"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"heading_collapsed":true,"id":"SfcNvgqiguxj"},"source":["# Using Pipeline and Performing a Grid Search for Optimal Parameters"]},{"cell_type":"code","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"71e41dd8-9242-45ee-924c-8a34a8efb364","showTitle":false,"title":""},"hidden":true,"id":"KUKBIt1Kguxj"},"source":["one_hot_encoder = OneHotEncoder(inputCols=['date_of_month',\n","                                                'day_of_week'],\n","                                     outputCols=['date_vec',\n","                                                  'day_vec'],\n","                                     dropLast=True)\n","vector_assember = VectorAssembler(inputCols=features,\n","                                  outputCol='features')\n","random_forest = RandomForestRegressor(featuresCol='features',\n","                                      labelCol='births')\n","stages = [one_hot_encoder, vector_assember, random_forest]\n","\n","pipeline = Pipeline(stages=stages)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"7f22a487-ae2a-4c7e-85bc-a15edfdc601d","showTitle":false,"title":""},"hidden":true,"id":"nCbc611Pguxj"},"source":["Note: The stages in a pipeline can be either *Transformers* or *Estimators*. An estimator fits a DataFrame to produce a Transformer."]},{"cell_type":"code","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"d3d1c4a4-9534-4292-b0c2-e894568b18fd","showTitle":false,"title":""},"hidden":true,"id":"BkZZSt2Nguxj"},"source":["random_forest.params"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"37cb006e-18b0-482a-86e5-e791db4af5ba","showTitle":false,"title":""},"hidden":true,"id":"doOPxRw2guxk"},"source":["params = ParamGridBuilder().addGrid(random_forest.numTrees, [20, 50, 100]).build()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"e5a25b89-173d-4125-aee4-8a669ea2e865","showTitle":false,"title":""},"hidden":true,"id":"bnoTfjU3guxk"},"source":["reg_evaluator = RegressionEvaluator(predictionCol='prediction', labelCol='births',\n","                                    metricName='mae')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"heading_collapsed":true,"hidden":true,"id":"ohAhhLT-guxk"},"source":["## Evaluate with Cross Validation to Find Optimal Model"]},{"cell_type":"code","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"679011e7-8b9b-4f45-a39a-2b82f8424d6b","showTitle":false,"title":""},"hidden":true,"id":"yAX-z1XDguxk"},"source":["cv = CrossValidator(\n","    estimator=pipeline,\n","    estimatorParamMaps=params,\n","    evaluator=reg_evaluator,\n","    parallelism=4\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"cf5035ad-0e62-46f4-b4b9-76bb218eff78","showTitle":false,"title":""},"hidden":true,"id":"40o3WPWdguxk"},"source":["cross_validated_model = cv.fit(df.cache())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"c22a7ec3-61ff-452b-9a12-b0ecce619762","showTitle":false,"title":""},"hidden":true,"id":"_2nHDqqGguxk"},"source":["cross_validated_model.avgMetrics"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"40d18fda-9c91-41a5-bd2d-853e2032d9dd","showTitle":false,"title":""},"hidden":true,"id":"QFizDk-wguxl"},"source":["cross_validated_model.bestModel"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"8c616ba9-a273-42ab-abd0-edd80ea2fbbb","showTitle":false,"title":""},"hidden":true,"id":"bUwXg81tguxl"},"source":["cross_validated_model.bestModel.stages"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"1517c851-5965-4f26-a229-d0e7df3dc894","showTitle":false,"title":""},"hidden":true,"id":"x9aoMwaQguxl"},"source":["cross_validated_model.bestModel.stages[2].getNumTrees"],"execution_count":null,"outputs":[]}]}